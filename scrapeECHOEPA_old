#!/usr/bin/env python3 
import csv
import os 
import sys
import pandas as pd
import mysql.connector
import glob
from sqlalchemy import create_engine
os.chdir(os.path.dirname(sys.argv[0]))
LARGE_TABLES=True
SMALL_TABLES=True
DOWNLOAD_ZIP=True
DOWNLOAD=True 
dbPostfixes=['a','b']
#dbTypes=['mysql+mysqlconnector','postgres']
dbTypes=['mysql+mysqlconnector','mysql+mysqlconnector']
with open('currentDBIndex') as x: currentDBIndex = x.read()
currentDBIndex=1-int(currentDBIndex)
x.close()
print(currentDBIndex)
with open('db_%s_private.csv' %(dbPostfixes[currentDBIndex]), newline='') as csvfile:
	reader = csv.DictReader(csvfile)
	for row in reader:	
		engine = create_engine('%s://%s:%s@%s/%s' %(dbTypes[currentDBIndex],row['user'],row['password'],row['host'],row['db']), echo=False)
filesWithNulls=['CASE_ENFORCEMENTS','ICIS_PERMITS','FRS_PROGRAM_LINKS']
largeTables=['POLL_RPT_COMBINED_EMISSIONS','NPDES_DMRS_FY2020','ECHO_EXPORTER','NPDES_EFF_VIOLATIONS','FRS_PROGRAM_LINKS','NPDES_INSPECTIONS','NPDES_QNCR_HISTORY','SDWA_VIOLATIONS','SDWA_PUB_WATER_SYSTEMS','SDWA_ENFORCEMENTS','ICIS_PERMITS','ICIS-AIR_FCES_PCES']
def truncate(table):
	print(table)
	try:
		engine.execute('truncate `%s`' %(table))
	except Exception as e:
		print (e.__class__.__name__)
		print("new table %s" %(table))
with open('files.csv', newline='') as csvfile:
	reader = csv.DictReader(csvfile)
	uniqueZips=[]
	tables=[]
	for row in reader:
		tables.append(row['CSV FILE'])
		if row['Location'] not in uniqueZips:
			uniqueZips.append(row['Location'])
	if DOWNLOAD_ZIP:
		for location in uniqueZips:
			if not os.path.isfile('zips/%s' %(location)):
				print("Getting %s" %(location))
				os.system("./wgetEPA %s" %(location))
				os.system("./unzipEPA %s" %(location))
			else:
				print("File %s  already exists" %(location))
				os.system("./unzipEPA %s" %(location))
			os.remove('./zips/%s' %(location))
	for nulledFile in filesWithNulls:	
		os.system("./stripNulls %s" %(nulledFile))

	for table in tables:
		if table not in largeTables and SMALL_TABLES:
			truncate(table)
			df=pd.read_csv('./CSV/%s.csv' %(table),low_memory=False)
			df.to_sql(table,engine,if_exists='append',index=False)	
			os.remove('./CSV/%s.csv' %(table))

	for table in largeTables:
		if table in tables and LARGE_TABLES:
			truncate(table)
			os.system("./chunkFile %s" %(table))
			chunks=glob.glob('./CSV/%s_[0-9]*.csv' %(table)) 
			for path in chunks:
				fileStem=path.split("/")[2].split(".")[0]
				df=pd.read_csv('./CSV/%s.csv' %(fileStem))
				df.to_sql(table,engine,if_exists='append', index=False)	
				os.remove('./CSV/%s.csv' %(fileStem))
			os.remove('./CSV/%s.csv' %(table))
engine.execute('update ECHO_EXPORTER set REGISTRY_ID= round(REGISTRY_ID,0)')
engine.execute('update ICIS_FEC_EPA_INSPECTIONS set REGISTRY_ID= round(REGISTRY_ID,0)')
engine.execute('update `ICIS-AIR_FACILITIES` set REGISTRY_ID= round(REGISTRY_ID,0)')
with open('currentDBIndex', 'w') as writer: 
	writer.write(str(currentDBIndex))